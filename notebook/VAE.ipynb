{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import argparse\n",
    "import os\n",
    "import json\n",
    "\n",
    "from keras.layers import Lambda, Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28) y_train shape: (60000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xb2d106c50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAD8ZJREFUeJzt3W+MleWZx/HfxcAI8ifyR2BCRyn4J0uIgpmQNa4bN9XGrjXYFzUlEVnTlMaUuDWN0fCmvtnEbLbt+mLTZLqQYkJta1oWXuhujdnokqwV/BOUxbVEZ+s4wx8dBSEQGObaF/PQTHHOfR/Oec55DlzfT2LmzLnOc57LM/zmOWfu57lvc3cBiGdK1Q0AqAbhB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8Q1NR27szMOJ2wAdOnT0/WT58+3aZOyjV1avqf3+joaJs6uby4u9XzuKbCb2Z3S3paUpekf3X3p5p5Pkxu+fLlyfr+/fsbfu4pU9Jv/sbGxhp+7py5c+cm60ePHm3q+c1qZ4DT2pt4229mXZL+RdLXJK2QtM7MVpTVGIDWauYz/xpJB939fXc/I+mXktaW0xaAVmsm/EskfTjh+8Hivj9jZhvNbK+Z7W1iXwBK1sxn/sk+UH3hg5S790vql/iDH9BJmjnyD0rqnfD9lyQNNdcOgHZpJvx7JF1vZl82s25J35K0q5y2ALRaw2/73X3UzDZJ+g+ND/VtdffGx5wuYytXrkzWH3/88WR93rx5yfrIyEjN2vr165PbtnIoT5LefPPNmrUTJ04kt3311VeT9cceeyxZZzgvralxfnd/XtLzJfUCoI04vRcIivADQRF+ICjCDwRF+IGgCD8QVFuv54/q3nvvTdZvuummZP32229P1o8dO1aztnTp0uS2zz33XLLe1dWVrD/00EPJ+tVXX12zdueddya3ffnll5P1nTt3Juu7d+9O1qPjyA8ERfiBoAg/EBThB4Ii/EBQhB8IiqG+Nvj000+T9dwlu8ePH0/Wm5mldvbs2cn6/Pnzk/XcZbk9PT3JekpumPHQoUMNPzc48gNhEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIzzt0HuktyrrroqWV+zZk2y/tprr9WsPfLII8ltH3zwwWR9YGAgWc/9v6U8+uijyXruHISFCxcm6wcPHrzoniLhyA8ERfiBoAg/EBThB4Ii/EBQhB8IivADQVkzyxib2YCkzyWdkzTq7n2Zx4dcM3nPnj3J+uLFi5P1o0ePJuu33HLLRfd0Xu7nPzg4mKz39vY2vO+PP/44WU/NUyBJu3btStZz04pfrtw9/cIVyjjJ52/cPf1TBNBxeNsPBNVs+F3S78zsdTPbWEZDANqj2bf9t7n7kJktlPSimb3r7q9MfEDxS4FfDECHaerI7+5DxdcjknZI+sIVKO7e7+59uT8GAmivhsNvZjPNbPb525K+KumdshoD0FrNvO1fJGlHMRwzVdIv3P3fS+kKQMs1HH53f1/SzSX2csl6+OGHk/XcdecjIyPJ+urVq5P1LVu2NFSTpLNnzybruTUHlixZkqzv2LGjZu3UqVPJbXP1FStWJOtIY6gPCIrwA0ERfiAowg8ERfiBoAg/EBRTd5cgd1nr6Ohosj51avrH8O677ybrDzzwQM3a+vXrk9t+9NFHyXpuWvHcJb+nT59ueNvc5cbd3d3JOtI48gNBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIzzl2B4eDhZnzt3brJ+6NChZD03np1ainratGlNPffY2Fiy/t577yXrU6bUPr7kestdbozmcOQHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAY5y9BbqnpGTNmJOu5pajPnTuXrF9xxRXJesqZM2eS9VxvXV1dDe87N46fO8fgmmuuSdZTr3tuWvAIOPIDQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFDZcX4z2yrp65KOuPvK4r55kn4laamkAUn3u3t6LefL2L59+5L13Dh8bl7/3Pz1qbH43Dh9q+V6T8mdQzA0NJSsM5afVs+R/+eS7r7gvickveTu10t6qfgewCUkG353f0XSyAV3r5W0rbi9TdJ9JfcFoMUa/cy/yN2HJan4urC8lgC0Q8vP7TezjZI2tno/AC5Oo0f+w2bWI0nF1yO1Huju/e7e5+59De4LQAs0Gv5dkjYUtzdI2llOOwDaJRt+M3tW0n9LutHMBs3s25KeknSXmf1B0l3F9wAuIdnP/O6+rkbpKyX3csnav39/sp673j83f33uev4qx/Jz+06N8+fOAchdz//BBx8k60jjDD8gKMIPBEX4gaAIPxAU4QeCIvxAUEzd3QapJbQlacGCBcl6bsirmUt6m7nktp7tU5fl5oYwc5f0Hjt2LFlHGkd+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiKcf42OHHiRLI+f/78ZD23lHXukuBWauY8gdzy4NOnT0/Wc+cJII0jPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ExTh/G/T09CTrufHuKVPSv6NT4925a+KbvZ4/JzUXQW6cPvf/fejQoYZ6wjiO/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QVHac38y2Svq6pCPuvrK470lJ35F0tHjYZnd/vlVNXuo+++yzZH3hwoXJeu48gNRYfqvn7c+tKZAaq291b0ir58j/c0l3T3L/T9x9VfEfwQcuMdnwu/srkkba0AuANmrmM/8mM9tnZlvNbG5pHQFoi0bD/1NJyyWtkjQs6Ue1HmhmG81sr5ntbXBfAFqgofC7+2F3P+fuY5J+JmlN4rH97t7n7n2NNgmgfA2F38wmXqb2DUnvlNMOgHapZ6jvWUl3SFpgZoOSfijpDjNbJcklDUj6bgt7BNAC2fC7+7pJ7t7Sgl4uWzNmzKhs360eK89dc9+MXO8zZ85s2b4j4Aw/ICjCDwRF+IGgCD8QFOEHgiL8QFBM3d0GuSW4c5fsXspSl+3mhvJy044PDAw00hIKHPmBoAg/EBThB4Ii/EBQhB8IivADQRF+IChr5/TIZhZyLubc1N1DQ0PJem4p69x4eEqrf/6pcf6TJ08mt82dH3HgwIFk/Z577knWL1funp4TvcCRHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeC4nr+EuSW2J41a1ayXuVS1Lmpt3O9NVPv7u5Obpub5+CGG25I1pHGkR8IivADQRF+ICjCDwRF+IGgCD8QFOEHgsqO85tZr6RnJC2WNCap392fNrN5kn4laamkAUn3u/unrWu1c1133XVNbT82NpasN7MMdup6+jI08/y5/6+zZ88m69dee23D+0Z9R/5RST9w97+Q9JeSvmdmKyQ9Iekld79e0kvF9wAuEdnwu/uwu79R3P5c0gFJSyStlbSteNg2Sfe1qkkA5buo95NmtlTSakm/l7TI3Yel8V8QktLnuALoKHWf229msyT9RtL33f14vZ/1zGyjpI2NtQegVeo68pvZNI0Hf7u7/7a4+7CZ9RT1HklHJtvW3fvdvc/d+8poGEA5suG38UP8FkkH3P3HE0q7JG0obm+QtLP89gC0Sj1v+2+TtF7S22b2VnHfZklPSfq1mX1b0h8lfbM1LXa+ZcuWJeu5j0ijo6PJ+vTp0y+6p3r33azcJb2p/eemHM9d0jt1avqf75w5c2rWjh8/ntw2gmz43X23pFo/wa+U2w6AduEMPyAowg8ERfiBoAg/EBThB4Ii/EBQTN1dgkWLFiXruUt2c+PduXqVU3/nNHOeQW7bXD01tffevXsb6ulywpEfCIrwA0ERfiAowg8ERfiBoAg/EBThB4JinL8EN954Y7J+8uTJZD03jt9KnTy1d27q7pze3t6aNcb5OfIDYRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCM85cgt1T06dOnk/Xc/PPNXtfejNxz5+YSSNVzzz1t2rRkPTdPwpVXXpmsR8eRHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCyo7zm1mvpGckLZY0Jqnf3Z82syclfUfS0eKhm939+VY12slyY925teBPnTqVrLfyev8pU5r7/Z8ba29mnD/3ug4MDCTrSKvnJJ9RST9w9zfMbLak183sxaL2E3f/p9a1B6BVsuF392FJw8Xtz83sgKQlrW4MQGtd1Hs+M1sqabWk3xd3bTKzfWa21czm1thmo5ntNTPmTQI6SN3hN7NZkn4j6fvuflzSTyUtl7RK4+8MfjTZdu7e7+597t5XQr8ASlJX+M1smsaDv93dfytJ7n7Y3c+5+5ikn0la07o2AZQtG34b/5PsFkkH3P3HE+7vmfCwb0h6p/z2ALRKPX/tv03Seklvm9lbxX2bJa0zs1WSXNKApO+2pMNLwK233pqsz5kzJ1k/d+5cst7MJb25obic3Pajo6PJemooMTfM+OGHHybry5YtS9ZvvvnmmrXt27cnt42gnr/275Y02b+ukGP6wOWCM/yAoAg/EBThB4Ii/EBQhB8IivADQTF1dwk2bdqUrC9Zkr4OKnfJ7pkzZ5L17u7umrXctOC5586dozBjxoxkPbXM9sjISHLbTz75JFnPvW4vvPBCsh4dR34gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCMpy0yOXujOzo5L+b8JdCyR93LYGLk6n9tapfUn01qgye7vW3a+u54FtDf8Xdm62t1Pn9uvU3jq1L4neGlVVb7ztB4Ii/EBQVYe/v+L9p3Rqb53al0Rvjaqkt0o/8wOoTtVHfgAVqST8Zna3mf2vmR00syeq6KEWMxsws7fN7K2qlxgrlkE7YmbvTLhvnpm9aGZ/KL5OukxaRb09aWYfFa/dW2b2txX11mtm/2lmB8xsv5n9fXF/pa9doq9KXre2v+03sy5J70m6S9KgpD2S1rn7/7S1kRrMbEBSn7tXPiZsZn8t6YSkZ9x9ZXHfP0oacfenil+cc9398Q7p7UlJJ6peublYUKZn4srSku6T9Heq8LVL9HW/Knjdqjjyr5F00N3fd/czkn4paW0FfXQ8d39F0oUzXqyVtK24vU3j/3jarkZvHcHdh939jeL255LOryxd6WuX6KsSVYR/iaSJS7EMqrOW/HZJvzOz181sY9XNTGJRsWz6+eXTF1bcz4WyKze30wUrS3fMa9fIitdlqyL8k63+00lDDre5+y2Svibpe8XbW9SnrpWb22WSlaU7QqMrXpetivAPSuqd8P2XJA1V0Mek3H2o+HpE0g513urDh88vklp8PVJxP3/SSSs3T7aytDrgteukFa+rCP8eSdeb2ZfNrFvStyTtqqCPLzCzmcUfYmRmMyV9VZ23+vAuSRuK2xsk7aywlz/TKSs311pZWhW/dp224nUlJ/kUQxn/LKlL0lZ3/4e2NzEJM1um8aO9ND6z8S+q7M3MnpV0h8av+jos6YeS/k3SryVdI+mPkr7p7m3/w1uN3u7Q+FvXP63cfP4zdpt7+ytJ/yXpbUnnlxnerPHP15W9dom+1qmC140z/ICgOMMPCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQ/w+ntMNZkkLdMgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[random.randint(0, x_train.shape[0])], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define params and helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size_ori = x_train.shape[1]\n",
    "x_train = np.reshape(x_train, [-1, img_size_ori])\n",
    "x_test = np.reshape(x_test, [-1, img_size_ori])\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    \"\"\"Reparameterization trick by sampling fr an isotropic unit Gaussian.\n",
    "    # Arguments:\n",
    "        args (tensor): mean and log of variance of Q(z|X)\n",
    "    # Returns:\n",
    "        z (tensor): sampled latent vector\n",
    "    \"\"\"\n",
    "\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    # by default, random_normal has mean=0 and std=1.0\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (img_size_ori, )\n",
    "intermediate_dim = 512\n",
    "batch_size = 128\n",
    "latent_dim = 2\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# VAE model = encoder + decoder\n",
    "# build encoder model\n",
    "inputs = Input(shape=input_shape, name='encoder_input')\n",
    "x = Dense(intermediate_dim, activation='relu')(inputs)\n",
    "z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
    "\n",
    "# use reparameterization trick to push the sampling out as input\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "\n",
    "# instantiate encoder model\n",
    "encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "    \n",
    "# build decoder model\n",
    "latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "x = Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
    "outputs = Dense(img_size_ori, activation='sigmoid')(x)\n",
    "\n",
    "# instantiate decoder model\n",
    "decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "    \n",
    "# instantiate VAE model\n",
    "outputs = decoder(encoder(inputs)[2])\n",
    "vae = Model(inputs, outputs, name='vae_mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   (None, 28)                0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              [(None, 2), (None, 2), (N 16900     \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 28)                15900     \n",
      "=================================================================\n",
      "Total params: 32,800\n",
      "Trainable params: 32,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_loss = mse(inputs, outputs)\n",
    "reconstruction_loss *= img_size_ori\n",
    "\n",
    "kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "kl_loss = K.sum(kl_loss, axis=-1)\n",
    "kl_loss *= -0.5\n",
    "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "vae.add_loss(vae_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.compile(optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1680000 samples, validate on 280000 samples\n",
      "Epoch 1/50\n",
      "1680000/1680000 [==============================] - 25s 15us/step - loss: 0.0287 - val_loss: 8.7956e-05\n",
      "Epoch 2/50\n",
      "1680000/1680000 [==============================] - 23s 14us/step - loss: 8.4703e-05 - val_loss: 8.4086e-05\n",
      "Epoch 3/50\n",
      "1680000/1680000 [==============================] - 23s 14us/step - loss: 8.4501e-05 - val_loss: 8.4109e-05\n",
      "Epoch 4/50\n",
      "1680000/1680000 [==============================] - 25s 15us/step - loss: 8.4502e-05 - val_loss: 8.4238e-05\n",
      "Epoch 5/50\n",
      "1680000/1680000 [==============================] - 24s 14us/step - loss: 8.4479e-05 - val_loss: 8.4130e-05\n",
      "Epoch 6/50\n",
      "1680000/1680000 [==============================] - 24s 14us/step - loss: 8.4459e-05 - val_loss: 8.4334e-05\n",
      "Epoch 7/50\n",
      "1680000/1680000 [==============================] - 27s 16us/step - loss: 8.4442e-05 - val_loss: 8.4261e-05\n",
      "Epoch 8/50\n",
      "1680000/1680000 [==============================] - 25s 15us/step - loss: 8.4416e-05 - val_loss: 8.3995e-05\n",
      "Epoch 9/50\n",
      "1680000/1680000 [==============================] - 26s 15us/step - loss: 8.4394e-05 - val_loss: 8.4225e-05\n",
      "Epoch 10/50\n",
      "1680000/1680000 [==============================] - 26s 15us/step - loss: 8.4371e-05 - val_loss: 8.4036e-05\n",
      "Epoch 11/50\n",
      "1680000/1680000 [==============================] - 22s 13us/step - loss: 8.4361e-05 - val_loss: 8.4039e-05\n",
      "Epoch 12/50\n",
      "1680000/1680000 [==============================] - 21s 13us/step - loss: 8.4340e-05 - val_loss: 8.3955e-05\n",
      "Epoch 13/50\n",
      "1680000/1680000 [==============================] - 22s 13us/step - loss: 8.4323e-05 - val_loss: 8.4108e-05\n",
      "Epoch 14/50\n",
      "1680000/1680000 [==============================] - 27s 16us/step - loss: 8.4316e-05 - val_loss: 8.4073e-05\n",
      "Epoch 15/50\n",
      "1680000/1680000 [==============================] - 23s 14us/step - loss: 8.4316e-05 - val_loss: 8.3942e-05\n",
      "Epoch 16/50\n",
      "1680000/1680000 [==============================] - 25s 15us/step - loss: 8.4298e-05 - val_loss: 8.3986e-05\n",
      "Epoch 17/50\n",
      "1680000/1680000 [==============================] - 25s 15us/step - loss: 8.4289e-05 - val_loss: 8.4008e-05\n",
      "Epoch 18/50\n",
      "1680000/1680000 [==============================] - 23s 13us/step - loss: 8.4277e-05 - val_loss: 8.3963e-05\n",
      "Epoch 19/50\n",
      "1680000/1680000 [==============================] - 22s 13us/step - loss: 8.4274e-05 - val_loss: 8.3892e-05\n",
      "Epoch 20/50\n",
      "1680000/1680000 [==============================] - 22s 13us/step - loss: 8.4263e-05 - val_loss: 8.4140e-05\n",
      "Epoch 21/50\n",
      "1680000/1680000 [==============================] - 24s 14us/step - loss: 8.4260e-05 - val_loss: 8.3970e-05\n",
      "Epoch 22/50\n",
      "1680000/1680000 [==============================] - 23s 14us/step - loss: 8.4256e-05 - val_loss: 8.3940e-05\n",
      "Epoch 23/50\n",
      "1680000/1680000 [==============================] - 23s 14us/step - loss: 8.4252e-05 - val_loss: 8.4046e-05\n",
      "Epoch 24/50\n",
      "1680000/1680000 [==============================] - 24s 14us/step - loss: 8.4249e-05 - val_loss: 8.3898e-05\n",
      "Epoch 25/50\n",
      "1680000/1680000 [==============================] - 23s 14us/step - loss: 8.4236e-05 - val_loss: 8.3907e-05\n",
      "Epoch 26/50\n",
      "1680000/1680000 [==============================] - 25s 15us/step - loss: 8.4241e-05 - val_loss: 8.3935e-05\n",
      "Epoch 27/50\n",
      "1680000/1680000 [==============================] - 22s 13us/step - loss: 8.4237e-05 - val_loss: 8.4145e-05\n",
      "Epoch 28/50\n",
      "1680000/1680000 [==============================] - 21s 13us/step - loss: 8.4234e-05 - val_loss: 8.3893e-05\n",
      "Epoch 29/50\n",
      "1680000/1680000 [==============================] - 23s 13us/step - loss: 8.4228e-05 - val_loss: 8.3933e-05\n",
      "Epoch 30/50\n",
      "1680000/1680000 [==============================] - 22s 13us/step - loss: 8.4229e-05 - val_loss: 8.3890e-05\n",
      "Epoch 31/50\n",
      "1680000/1680000 [==============================] - 23s 14us/step - loss: 8.4224e-05 - val_loss: 8.4002e-05\n",
      "Epoch 32/50\n",
      "1680000/1680000 [==============================] - 24s 14us/step - loss: 8.4226e-05 - val_loss: 8.3889e-05\n",
      "Epoch 33/50\n",
      "1680000/1680000 [==============================] - 23s 14us/step - loss: 8.4220e-05 - val_loss: 8.3871e-05\n",
      "Epoch 34/50\n",
      "1680000/1680000 [==============================] - 25s 15us/step - loss: 8.4219e-05 - val_loss: 8.3922e-05\n",
      "Epoch 35/50\n",
      "1680000/1680000 [==============================] - 24s 14us/step - loss: 8.4215e-05 - val_loss: 8.3986e-05\n",
      "Epoch 36/50\n",
      "1680000/1680000 [==============================] - 23s 14us/step - loss: 8.4217e-05 - val_loss: 8.3985e-05\n",
      "Epoch 37/50\n",
      "1680000/1680000 [==============================] - 23s 14us/step - loss: 8.4212e-05 - val_loss: 8.4013e-05\n",
      "Epoch 38/50\n",
      "1680000/1680000 [==============================] - 25s 15us/step - loss: 8.4216e-05 - val_loss: 8.4010e-05\n",
      "Epoch 39/50\n",
      "1680000/1680000 [==============================] - 25s 15us/step - loss: 8.4207e-05 - val_loss: 8.3888e-05\n",
      "Epoch 40/50\n",
      "1680000/1680000 [==============================] - 25s 15us/step - loss: 8.4208e-05 - val_loss: 8.4056e-05\n",
      "Epoch 41/50\n",
      "1680000/1680000 [==============================] - 24s 14us/step - loss: 8.4206e-05 - val_loss: 8.3887e-05\n",
      "Epoch 42/50\n",
      "1680000/1680000 [==============================] - 24s 14us/step - loss: 8.4209e-05 - val_loss: 8.3894e-05\n",
      "Epoch 43/50\n",
      "1680000/1680000 [==============================] - 26s 16us/step - loss: 8.4203e-05 - val_loss: 8.3883e-05\n",
      "Epoch 44/50\n",
      "1680000/1680000 [==============================] - 26s 15us/step - loss: 8.4205e-05 - val_loss: 8.3903e-05\n",
      "Epoch 45/50\n",
      "1680000/1680000 [==============================] - 25s 15us/step - loss: 8.4201e-05 - val_loss: 8.4083e-05\n",
      "Epoch 46/50\n",
      "1680000/1680000 [==============================] - 25s 15us/step - loss: 8.4206e-05 - val_loss: 8.3988e-05\n",
      "Epoch 47/50\n",
      "1680000/1680000 [==============================] - 25s 15us/step - loss: 8.4202e-05 - val_loss: 8.3893e-05\n",
      "Epoch 48/50\n",
      "1680000/1680000 [==============================] - 25s 15us/step - loss: 8.4203e-05 - val_loss: 8.3908e-05\n",
      "Epoch 49/50\n",
      "1680000/1680000 [==============================] - 24s 14us/step - loss: 8.4200e-05 - val_loss: 8.3907e-05\n",
      "Epoch 50/50\n",
      "1680000/1680000 [==============================] - 23s 14us/step - loss: 8.4199e-05 - val_loss: 8.3942e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb2f23a630>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.fit(x_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_test, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.save_weights('../model/vae_mlp_fsmnist.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
